{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Izin bertnya apakah studi idenpenden mitra pro...\n",
       "1                               Dapat uang saku gaksih\n",
       "2            @rwrt1.0 kelas full english kak batch ini\n",
       "3                        Saya, saya bang ga lolos msib\n",
       "4                                                   🔥🔥\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori = pd.read_csv('data/df_kotor.csv')\n",
    "df = df_ori[\"comment\"]\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casefolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove sentence which contains only one word\n",
    "def remove_sentence(text): \n",
    "    word = text.split()\n",
    "    wordCount = len(word)\n",
    "    if(wordCount<=1):\n",
    "        text = ''\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    izin bertnya apakah studi idenpenden mitra pro...\n",
       "1                               dapat uang saku gaksih\n",
       "2                     kelas full english kak batch ini\n",
       "3                         saya saya bang ga lolos msib\n",
       "4                                                     \n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def casefolding(text):\n",
    "    # mengubah huruf kapital menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    \n",
    "    # menghapus mention dan link\n",
    "    text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text)\n",
    "    \n",
    "    # menghapus semua karakter selain huruf dan angka\n",
    "    text = re.sub(r'[^a-z0-9 ]', '', text)\n",
    "    \n",
    "    # menghapus angka\n",
    "    text = re.sub(r\"\\b\\d+\\b\", \" \", text)\n",
    "    return text\n",
    "\n",
    "df = df.apply(remove_sentence)\n",
    "df = df.apply(casefolding)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [izin, bertnya, apakah, studi, idenpenden, mit...\n",
       "1                          [dapat, uang, saku, gaksih]\n",
       "2              [kelas, full, english, kak, batch, ini]\n",
       "3                  [saya, saya, bang, ga, lolos, msib]\n",
       "4                                                   []\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenization(text):\n",
    "    # memecah kalimat menjadi kata\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "df = df.apply(tokenization)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Slangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slang = pd.read_csv('src/colloquial-indonesian-lexicon.csv')\n",
    "slang_dict = dict(zip(df_slang['slang'], df_slang['formal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "slangword = {}\n",
    "\n",
    "with open('src/combined_slang_words.txt', 'r') as f:\n",
    "    slangword = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [izin, bertnya, apakah, studi, idenpenden, mit...\n",
       "1                          [dapat, uang, saku, gaksih]\n",
       "2              [kelas, full, english, kak, batch, ini]\n",
       "3               [saya, saya, bang, tidak, lolos, msib]\n",
       "4                                                   []\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_slang(text):\n",
    "    return [slang_dict.get(token, token) for token in text]\n",
    "\n",
    "def replace_slang_v2(text):\n",
    "    return [slangword.get(token, token) for token in text]\n",
    "\n",
    "df = df.apply(replace_slang)\n",
    "df = df.apply(replace_slang_v2)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# stop_words = set(stopwords.words('indonesian', 'english'))\n",
    "# stop_words.update([\n",
    "#     'min', 'ga', 'gak', 'iya', 'ya', 'sih', 'gk', 'kak', 'bang', 'pak', 'sir', 'bro', 'sob', 'sdr','mbak', 'mba', 'kakak', 'kakaknya', 'kakakku', 'nya', 'mas', \n",
    "# ])\n",
    "\n",
    "# def remove_stopword(text):\n",
    "#     return [word for word in text if not word in stop_words]\n",
    "\n",
    "# df = df.apply(remove_stopword)\n",
    "# df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# def stemming(text):\n",
    "#     factory = StemmerFactory()\n",
    "#     stemmer = factory.create_stemmer()\n",
    "#     return [stemmer.stem(word) for word in text]\n",
    "\n",
    "# df = df.apply(stemming)\n",
    "# df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_ori.copy()\n",
    "df_clean = df_clean.drop(columns=['clean', 'topic'])\n",
    "df_clean[\"clean\"] = df.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Izin bertnya apakah studi idenpenden mitra pro...</td>\n",
       "      <td>izin bertnya apakah studi idenpenden mitra pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dapat uang saku gaksih</td>\n",
       "      <td>dapat uang saku gaksih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@rwrt1.0 kelas full english kak batch ini</td>\n",
       "      <td>kelas full english kak batch ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saya, saya bang ga lolos msib</td>\n",
       "      <td>saya saya bang tidak lolos msib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🔥🔥</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>@spontanahuy tanggal 15 terakhirnya 🙏🏻 ada bbr...</td>\n",
       "      <td>tanggal terakhirnya ada beberapa perusahaan ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>@spontanahuy ga ush berharap lgi udh tgl segin...</td>\n",
       "      <td>tidak perlu berharap lagi sudah tanggal segini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>@spontanahuy asliii butuh kepastian</td>\n",
       "      <td>asli butuh kepastian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>Siapa saja yg lolos utk ikut survei diinfokan ...</td>\n",
       "      <td>siapa saja yang lolos untuk ikut survei diinfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>Jadi min untuk pengumuman magang merdeka nya u...</td>\n",
       "      <td>jadi min untuk pengumuman magang merdeka nya s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "0    Izin bertnya apakah studi idenpenden mitra pro...   \n",
       "1                               Dapat uang saku gaksih   \n",
       "2            @rwrt1.0 kelas full english kak batch ini   \n",
       "3                        Saya, saya bang ga lolos msib   \n",
       "4                                                   🔥🔥   \n",
       "..                                                 ...   \n",
       "577  @spontanahuy tanggal 15 terakhirnya 🙏🏻 ada bbr...   \n",
       "578  @spontanahuy ga ush berharap lgi udh tgl segin...   \n",
       "579                @spontanahuy asliii butuh kepastian   \n",
       "580  Siapa saja yg lolos utk ikut survei diinfokan ...   \n",
       "581  Jadi min untuk pengumuman magang merdeka nya u...   \n",
       "\n",
       "                                                 clean  \n",
       "0    izin bertnya apakah studi idenpenden mitra pro...  \n",
       "1                               dapat uang saku gaksih  \n",
       "2                     kelas full english kak batch ini  \n",
       "3                      saya saya bang tidak lolos msib  \n",
       "4                                                       \n",
       "..                                                 ...  \n",
       "577  tanggal terakhirnya ada beberapa perusahaan ya...  \n",
       "578  tidak perlu berharap lagi sudah tanggal segini...  \n",
       "579                               asli butuh kepastian  \n",
       "580  siapa saja yang lolos untuk ikut survei diinfo...  \n",
       "581  jadi min untuk pengumuman magang merdeka nya s...  \n",
       "\n",
       "[582 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean.drop(columns=['Unnamed: 0'])\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_clean.to_csv('data/df_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1961e4fab7c657ac053f9fdb2ae9561ee61e35aef124aaa5e4d96292a32a9f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
